\hypertarget{index_intro_sec}{}\section{Introduction}\label{index_intro_sec}
Hey this is Sriram Maddirala and this is the intro page for my iteration3 for 3081W I worked quite a bit on it so hopefully you enjoy it as much as I did\hypertarget{index_overview}{}\section{overview}\label{index_overview}
This project is a Braitenberg Vehicle simulator in which robot behavior is visualized within a graphics window implemented through a model-\/view-\/controller architecture which means that there is a model responsible for holding the data, a viewer that gives an interface to interact with and/or view the data and a controller that manipulates the model and updates the viewer. The game is essentially to avoid the lights and walls while hitting the foods with the robot\hypertarget{index_Technical}{}\section{Overview}\label{index_Technical}
The simulation starts in \mbox{\hyperlink{main_8cc}{main.\+cc}} which instantiates and calls the run function of the \mbox{\hyperlink{class_controller}{Controller}} which sets the entire project into motion. The \mbox{\hyperlink{class_controller}{Controller}} then initializes the arena and the \mbox{\hyperlink{class_graphics_arena_viewer}{Graphics\+Arena\+Viewer}} which pops up with an interface that presents the arena and a G\+UI remote control. This \mbox{\hyperlink{class_arena}{Arena}} environment will have multiple robots, as well as stimuli such as lights and food where the robots exhibit different behavior in reaction to those stimuli. Some robots are attracted to the light while some fear the light and the relationship to food will change over time as the robot gets hungrier. This behavior is implemented through sensors for each stimuli. The sensors are stored in the robot. The pointers to these robots are stored in the arena and are accessed by the arena. The arena iterates through all the arena entities for every robot at each time step and then passes the positional information of that entity to the robot sensors. It also checks for collisions between every entity and every mobile entity and then calls the handlecollision method of the mobile entity where the following action is taken. If the mobile entity is a robot and it is colliding with a light or food, it passes through it. If the robot is colliding with a wall or another robot it begins an arc reversal motion. If the mobile entity is a light then if it collides with a wall or another light it begins an arc reversal. Both arc reversals are conducted through a finite state automata that is initiated in the handlecollision and is advanced with regards to time in the Timestep\+Update method. This same Timestep\+Update method of the mobile entities also, depending on the arc traversal status, behavior and for a robot hunger or starvation, sets the velocity of their respective motionhandlers through the sensor readings. This change in velocity updates the position and heading of the entity with a call to motion\+Behavior\+Differential and then resets the sensor readings. If the entity is a \mbox{\hyperlink{class_robot}{Robot}} and has fear, the reading from the right sensor impacts the velocity of the right wheel and the left sensor impacts the left wheel with respect to the lights. If the entity is a \mbox{\hyperlink{class_robot}{Robot}} and has exploratory behavior then the reading from the right sensor impacts the velocity of the left wheel, and the left sensor impacts the right wheel and the left sensor impacts the right wheel with respect to the lights. If the entity is a robot and senses food it is aggressive meaning the sensors have a positive correlation between the right sensor and left wheel, and between the left sensor and right wheel. If the entity is a \mbox{\hyperlink{class_robot}{Robot}} and is really hungry then it ignores and goes through the lights without care for light sensor readings. If the robot isn’t hungry then it would not go towards the food even when it is close enough to sense it. The \mbox{\hyperlink{class_robot}{Robot}} eats food and resets its hunger and starvation status when it is around 5 units away from the food if it is hungry. The \mbox{\hyperlink{class_graphics_arena_viewer}{Graphics\+Arena\+Viewer}} passes information to the model through a communication class that it uses to indicate certain signals to the controller which takes appropriate action and indicates its own situation appropriate signal to the arena. The G\+UI interface possesses the ability to change the number of robots, number of lights, sensitivity of robots to light, percentage of robots with Fear-\/based behavior, the ability to play/pause the simulation and start a new game, the ability to toggle food on and off as well as the functionality to change the number of \mbox{\hyperlink{class_food}{Food}} objects. These changes are all implemented after a new Game is called. When the new game is called the controller destroys the old arena, creates a new arenaparams, which is designed to hold all the \mbox{\hyperlink{class_arena}{Arena}} and G\+UI relevant data, with the new values that need to be implemented and then creates a new arena with those params and calls the viewer on the arena. Once the data is inside the arena, the number of robots, number of lights and the number of food objects are all specified through for loops which call the appropriate entity\+Factory method, entityfactory being the creator of entities, the specific number of times necessary for each entity to stay in keeping with the requested changes. The food toggle is used as a conditional throughout arena to implement the no food/food scenarios accordingly. In entity\+Factory, the percentage of robots with fear-\/based behavior is implemented through setting the robot’s behavior after it is created depending on how many are to be created in that step as well as how many of those have to be fear-\/based. After each robot is created the sensors, which are created in the robots themselves, are then called and the sensitivity to light is set through a setter method that acts on a pre-\/existing constant to adjust according to the request.